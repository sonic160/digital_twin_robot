{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 3\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this WP, you will work on a given training dataset. Your goal is to develop a fault detection model using the regression algorithms learnt in the class, in order to achieve best F1 score。\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Develop a regression model to predict the reference value for motor temperature.\n",
    "- Task 2: Develop a fault detection model using the regression model you developed in Task 1.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the process and results of the above tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch with your name, based on the \"main\" branch and switch to your own branch.\n",
    "- Copy this notebook to the work space of your group, and rename it to TD_WP_3_Your name.ipynb\n",
    "- After finishing this task, push your changes to the github repository of your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Predict normal behaviors through regression models\n",
    "\n",
    "In this task, let us try to develop a best regression model to predict the normal behaviors of a given motor. In this exercise, we can use motor 6 as an example. You can easilily generate the approach to other models for the data challenge.\n",
    "\n",
    "We can use all the dataset where motor 6 works normally as our dataset. Then, we can run a cross validation (based on sequence, not points) to test the performances of the developed model.\n",
    "\n",
    "In this example, we mainly use the following performance metrics:\n",
    "- max error: The max error between the predicted and the true values.\n",
    "- Mean root squared error: The mean root squared error between the predicted and the true values.\n",
    "- Out-of-boundary rate: The percentage that the residual error between the predicted and the true values is larger than a given threshold. Here, we set the thresold to be $3$ degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 1: Only use the features at the current moment.\n",
    "\n",
    "[This notebook](demo_regression_mdl.ipynb) provides a basic demonstration of how to set up the experiment. Let us start by considering only using the features from the current moment. In the notebook, we show a baseline using a simple linear regression with all the features. Could you please try to improve the performance of the model?\n",
    "\n",
    "A few possible directions:\n",
    "- Feature selection?\n",
    "- Smoothing?\n",
    "- Removing sequence-to-sequence variablity? Adding features regarding time dynamics (see the TD for last lecture).\n",
    "- Changing to other regression models? For this, you can try different regression models from [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "\n",
    "Put your code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "from utility import read_all_test_data_from_path\n",
    "from utility import read_all_test_data_from_path, show_reg_result,extract_selected_feature, prepare_sliding_window, FaultDetectReg\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import f_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_int = 20\n",
    "\n",
    "# Subfunction for data preprocessing.\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''\n",
    "    \n",
    "    # Function to design a Butterworth low-pass filter\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        nyquist = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "\n",
    "    # Function to apply the Butterworth low-pass filter\n",
    "    def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "        b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "        filtered_data = filtfilt(b, a, data)\n",
    "        return filtered_data\n",
    "\n",
    "\n",
    "    # Set parameters for the low-pass filter\n",
    "    cutoff_frequency = .8  # Adjust as needed\n",
    "    sampling_frequency = 10  # Assuming your data is evenly spaced in time\n",
    "\n",
    "\n",
    "    def customized_outlier_removal(df: pd.DataFrame):\n",
    "        ''' # Description\n",
    "        Remove outliers from the dataframe based on defined valid ranges. \n",
    "        Define a valid range of temperature and voltage. \n",
    "        Use ffil function to replace the invalid measurement with the previous value.\n",
    "        '''\n",
    "        df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "        df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "        df['position'] = df['position'].ffill()\n",
    "        df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "        df['position'] = df['position'].rolling(window=20, min_periods=1).mean()\n",
    "        df['position'] = df['position'].round()\n",
    "\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "        df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "        df['temperature'] = df['temperature'].rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "        # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "        # Define your threshold\n",
    "        threshold = 5\n",
    "        # Shift the 'temperature' column by one row to get the previous temperature\n",
    "        prev_tmp = df['temperature'].shift(1)\n",
    "        # Calculate the absolute difference between current and previous temperature\n",
    "        temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "        # Set the temperature to NaN where the difference is larger than the threshold\n",
    "        df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "        df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "        df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "        df['voltage'] = df['voltage'].ffill()\n",
    "        df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "        df['voltage'] = df['voltage'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "\n",
    "    def cal_diff(df: pd.DataFrame, n_int: int):\n",
    "        ''' # Description\n",
    "        Calculate the difference between the current and previous n data point.\n",
    "        '''\n",
    "        # Tranform the features relative to the first data point.\n",
    "        df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "        df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "        df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "        # Calculate the difference between the current and previous n data point.\n",
    "        df['temperature_diff'] = df['temperature'].diff(n_int)\n",
    "        df['voltage_diff'] = df['voltage'].diff(n_int)\n",
    "        df['position_diff'] = df['position'].diff(n_int)   \n",
    "\n",
    "    # Start processing.\n",
    "    customized_outlier_removal(df)\n",
    "    cal_diff(df, n_int)\n",
    "\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "df_data = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the folders in the base_dictionary\n",
    "path_list = os.listdir(base_dictionary)\n",
    "# Only keep the folders, not the excel file.\n",
    "path_list = path_list[:-1]\n",
    "\n",
    "# Read the data.\n",
    "df_data_smoothing = pd.DataFrame()\n",
    "for tmp_path in path_list:\n",
    "    path = base_dictionary + tmp_path\n",
    "    # Read the data with the customized outlier removal function.\n",
    "    tmp_df = read_all_csvs_one_test(path, tmp_path, pre_processing)\n",
    "    df_data_smoothing = pd.concat([df_data_smoothing, tmp_df])\n",
    "    df_data_smoothing = df_data_smoothing.reset_index(drop=True)\n",
    "\n",
    "# Read the test conditions\n",
    "df_test_conditions = pd.read_excel(base_dictionary+'Test conditions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_id = ['20240105_164214', \n",
    "    '20240105_165300', \n",
    "    '20240105_165972', \n",
    "    '20240320_152031', \n",
    "    '20240320_153841', \n",
    "    '20240320_155664', \n",
    "    '20240321_122650', \n",
    "    '20240325_135213', \n",
    "    '20240426_141190', \n",
    "    '20240426_141532', \n",
    "    '20240426_141602', \n",
    "    '20240426_141726', \n",
    "    '20240426_141938', \n",
    "    '20240426_141980', \n",
    "    '20240503_164435']\n",
    "df_data = df_data[df_data['test_condition'].isin(normal_test_id)]\n",
    "df_data_smoothing = df_data_smoothing[df_data_smoothing['test_condition'].isin(normal_test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Steps for Linear Regression\n",
    "linear_regression_steps = [\n",
    "    ('Normalizer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    #('Standardizer', StandardScaler),  # Step 1: Standardization\n",
    "    ('regressor', LinearRegression())    # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Steps for Ridge Regression\n",
    "ridge_regression_steps = [\n",
    "    ('Normalizer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    #('Standardizer', StandardScaler),  # Step 1: Standardization\n",
    "    ('regressor', Ridge())               # Step 2: Ridge Regression\n",
    "]\n",
    "\n",
    "# Steps for Lasso Regression\n",
    "lasso_regression_steps = [\n",
    "    ('Normalizer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    #('Standardizer', StandardScaler),  # Step 1: Standardizatio\n",
    "    ('regressor', Lasso())               # Step 2: Lasso Regression\n",
    "]\n",
    "\n",
    "# Steps for ElasticNet Regression\n",
    "elasticnet_regression_steps = [\n",
    "    ('Normalizer', MinMaxScaler()),  # Step 1: Normalization\n",
    "    #('Standardizer', StandardScaler),  # Step 1: Standardization\n",
    "    ('regressor', ElasticNet())          # Step 2: ElasticNet Regression\n",
    "]\n",
    "\n",
    "# Steps for Decision Tree Regression\n",
    "decision_tree_steps = [\n",
    "    ('regressor', DecisionTreeRegressor())  # Step 2: Decision Tree Regressor\n",
    "]\n",
    "\n",
    "# Initialize Pipelines for each model\n",
    "mdl_linear_regression = Pipeline(linear_regression_steps)\n",
    "mdl_ridge_regression = Pipeline(ridge_regression_steps)\n",
    "mdl_lasso_regression = Pipeline(lasso_regression_steps)\n",
    "mdl_elasticnet_regression = Pipeline(elasticnet_regression_steps)\n",
    "mdl_decision_tree = Pipeline(decision_tree_steps)\n",
    "\n",
    "# List of models to be used in GridSearchCV\n",
    "models = [\n",
    "    ('Linear Regression', mdl_linear_regression),\n",
    "    ('Ridge Regression', mdl_ridge_regression),\n",
    "    ('Lasso Regression', mdl_lasso_regression),\n",
    "    ('ElasticNet Regression', mdl_elasticnet_regression),\n",
    "    ('Decision Tree Regression', mdl_decision_tree),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import run_cv_one_motor\n",
    "\n",
    "\n",
    "def run_all_motors(df_data, mdl, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "            prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    all_results = []\n",
    "    # Loop over all the six motors.\n",
    "    for i in range(1, 7):\n",
    "        print(f'Model for predicting temperature of motor {i}:')\n",
    "        # Run cross validation.\n",
    "        df_perf = run_cv_one_motor(motor_idx=i, df_data=df_data, mdl=mdl, feature_list=feature_list,\n",
    "                n_fold=n_fold, threshold=threshold, window_size=window_size, sample_step=sample_step,\n",
    "            prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, mdl_type=mdl_type)\n",
    "        all_results.append(df_perf)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models_motor6(df_data, models, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "                   prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    summary_results = []\n",
    "    for name, mdl in models:\n",
    "        print(f'Running model: {name}')\n",
    "        df_perf  = run_cv_one_motor(motor_idx=6, df_data=df_data, mdl=mdl, feature_list=feature_list,\n",
    "                n_fold=n_fold, threshold=threshold, window_size=window_size, sample_step=sample_step,\n",
    "            prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, mdl_type=mdl_type)\n",
    "        \n",
    "        summary_results.append((name, df_perf))\n",
    "    \n",
    "    return summary_results\n",
    "\n",
    "\n",
    "def run_all_models(df_data, models, feature_list, n_fold=5, threshold=3, window_size=1, sample_step=1,\n",
    "                   prediction_lead_time=1, single_run_result=True, mdl_type='reg'):\n",
    "    summary_results = []\n",
    "    for name, mdl in models:\n",
    "        print(f'Running model: {name}')\n",
    "        all_results = run_all_motors(df_data, mdl, feature_list, n_fold=n_fold, threshold=threshold, \n",
    "                                     window_size=window_size, sample_step=sample_step,\n",
    "                                     prediction_lead_time=prediction_lead_time, single_run_result=single_run_result, \n",
    "                                     mdl_type=mdl_type)\n",
    "        \n",
    "        df_all_results = pd.concat(all_results, keys=[f'Motor_{i}' for i in range(1, 7)])\n",
    "        summary_results.append((name, df_all_results))\n",
    "    \n",
    "    return summary_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: Linear Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0  13.693682  4.926842              0.619834\n",
      "1   6.438077  2.220468              0.246692\n",
      "2  14.082472  7.054126              0.543295\n",
      "3   5.928427  2.883518              0.262097\n",
      "4   9.472806  5.735191              0.799173\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 9.9231 +- 3.8673\n",
      "RMSE: 4.5640 +- 2.0013\n",
      "Exceed boundary rate: 0.4942 +- 0.2379\n",
      "\n",
      "\n",
      "Running model: Ridge Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0  13.564431  4.859087              0.615732\n",
      "1   6.337341  2.206610              0.246692\n",
      "2  13.918247  6.962545              0.525654\n",
      "3   5.869100  2.855020              0.262097\n",
      "4   9.472488  5.738678              0.799764\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 9.8323 +- 3.8300\n",
      "RMSE: 4.5244 +- 1.9805\n",
      "Exceed boundary rate: 0.4900 +- 0.2367\n",
      "\n",
      "\n",
      "Running model: Lasso Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   6.358686  1.139367              0.041329\n",
      "1   2.785689  0.841022              0.000000\n",
      "2   8.998435  3.407160              0.429609\n",
      "3   3.635089  1.367069              0.030914\n",
      "4   7.457042  4.002409              0.660957\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 5.8470 +- 2.6005\n",
      "RMSE: 2.1514 +- 1.4457\n",
      "Exceed boundary rate: 0.2326 +- 0.2973\n",
      "\n",
      "\n",
      "Running model: ElasticNet Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   6.358686  1.139367              0.041329\n",
      "1   2.785689  0.841022              0.000000\n",
      "2   8.998435  3.407160              0.429609\n",
      "3   3.635089  1.367069              0.030914\n",
      "4   7.457042  4.002409              0.660957\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 5.8470 +- 2.6005\n",
      "RMSE: 2.1514 +- 1.4457\n",
      "Exceed boundary rate: 0.2326 +- 0.2973\n",
      "\n",
      "\n",
      "Running model: Decision Tree Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0       5.00  2.243931              0.083991\n",
      "1       6.00  1.160005              0.004726\n",
      "2       9.60  3.181970              0.358008\n",
      "3       4.60  1.365352              0.057796\n",
      "4       9.05  4.440423              0.539870\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 6.8500 +- 2.3243\n",
      "RMSE: 2.4783 +- 1.3580\n",
      "Exceed boundary rate: 0.2089 +- 0.2302\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature','data_motor_1_voltage',\n",
    "       'data_motor_1_temperature_diff', 'data_motor_1_voltage_diff','data_motor_1_position_diff', \n",
    "       'data_motor_2_position','data_motor_2_temperature', 'data_motor_2_voltage', \n",
    "       'data_motor_2_temperature_diff', 'data_motor_2_voltage_diff', 'data_motor_2_position_diff',\n",
    "       'data_motor_3_position', 'data_motor_3_temperature','data_motor_3_voltage',\n",
    "       'data_motor_3_temperature_diff', 'data_motor_3_voltage_diff','data_motor_3_position_diff', \n",
    "       'data_motor_4_position','data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "       'data_motor_4_temperature_diff', 'data_motor_4_voltage_diff', 'data_motor_4_position_diff',\n",
    "       'data_motor_5_position', 'data_motor_5_temperature','data_motor_5_voltage',\n",
    "       'data_motor_5_temperature_diff', 'data_motor_5_voltage_diff','data_motor_5_position_diff', \n",
    "       'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage',\n",
    "       'data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff']\n",
    "\n",
    "\n",
    "selected_features= ['time','data_motor_1_position',  'data_motor_1_temperature', \n",
    "                    'data_motor_2_position',  \n",
    "                    'data_motor_3_position',  \n",
    "                    'data_motor_4_position', 'data_motor_4_temperature',\n",
    "                    'data_motor_5_position', 'data_motor_5_temperature',\n",
    "                    'data_motor_6_position', 'data_motor_6_temperature', \n",
    "                    'data_motor_1_voltage']\n",
    "\n",
    "threshold = 1\n",
    "window_size = 1\n",
    "sample_step = 1\n",
    "prediction_lead_time = 1 # We add the temperature measurement up to 1 point before the current time.\n",
    "\n",
    "#all_model_results = run_all_models(df_data=df_data_smoothing, models=models, feature_list=selected_features, threshold=threshold, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, single_run_result=False)\n",
    "\n",
    "all_model_results = run_all_models_motor6(df_data=df_data_smoothing, models=models, feature_list=selected_features, threshold=threshold, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, single_run_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the results - Only using features from the current moment\n",
      "\n",
      "| Model                   | Max error | RMSE  | Exceed boundary rate |\n",
      "|-------------------------|-----------|-------|----------------------|\n",
      "| Linear Regression        |     9.92 |   4.56 |   0.49 |\n",
      "| Ridge Regression         |     9.83 |   4.52 |   0.49 |\n",
      "| Lasso Regression         |     5.85 |   2.15 |   0.23 |\n",
      "| ElasticNet Regression    |     5.85 |   2.15 |   0.23 |\n",
      "| Decision Tree Regression |     6.85 |   2.48 |   0.21 |\n",
      "\n",
      "The best model is Lasso Regression with a Mean Squared Error (RMSE) of 2.15.\n"
     ]
    }
   ],
   "source": [
    "summary_data = {\n",
    "    'Model': [],\n",
    "    'Max error': [],\n",
    "    'RMSE': [],\n",
    "    'Exceed boundary rate': []\n",
    "}\n",
    "\n",
    "for model_name, df_results in all_model_results:\n",
    "    max_error = df_results['Max error'].mean()\n",
    "    mse = df_results['RMSE'].mean()\n",
    "    exceed_boundary_rate = df_results['Exceed boundary rate'].mean()\n",
    "    \n",
    "    summary_data['Model'].append(model_name)\n",
    "    summary_data['Max error'].append(f'{max_error:.2f}')\n",
    "    summary_data['RMSE'].append(f'{mse:.2f}')\n",
    "    summary_data['Exceed boundary rate'].append(f'{exceed_boundary_rate:.2f}')\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Summary of the results - Only using features from the current moment\\n\")\n",
    "print(\"| Model                   | Max error | RMSE  | Exceed boundary rate |\")\n",
    "print(\"|-------------------------|-----------|-------|----------------------|\")\n",
    "\n",
    "for model_name, df_results in all_model_results:\n",
    "    max_error = df_results['Max error'].mean()\n",
    "    mse = df_results['RMSE'].mean()\n",
    "    exceed_boundary_rate = df_results['Exceed boundary rate'].mean()\n",
    "    \n",
    "    print(f\"| {model_name.ljust(24)} | {max_error:8.2f} | {mse:6.2f} | {exceed_boundary_rate:6.2f} |\")\n",
    "\n",
    "best_model = summary_df.loc[summary_df['RMSE'].idxmin()]\n",
    "print(f\"\\nThe best model is {best_model['Model']} with a Mean Squared Error (RMSE) of {best_model['RMSE']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Only using features from the current moment**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model                   | Max error | RMSE  | Exceed boundary rate |\n",
    "|-------------------------|-----------|-------|----------------------|\n",
    "| Linear Regression        |     9.92 |   4.56 |   0.49 |\n",
    "| Ridge Regression         |     9.83 |   4.52 |   0.49 |\n",
    "| Lasso Regression         |     5.85 |   2.15 |   0.23 |\n",
    "| ElasticNet Regression    |     5.85 |   2.15 |   0.23 |\n",
    "| Decision Tree Regression |     6.85 |   2.48 |   0.21 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-task 2: Include the features in the past\n",
    "\n",
    "Now, let's consider using the sliding window approach to include the past in the regression model as well. Please have a look at the demo notebook, run your experiment, and report the best models you could have if you apply the sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: Linear Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   0.079316  0.009911                   0.0\n",
      "1   0.052429  0.006249                   0.0\n",
      "2   0.068871  0.007215                   0.0\n",
      "3   0.053548  0.009681                   0.0\n",
      "4   0.051164  0.009095                   0.0\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 0.0611 +- 0.0125\n",
      "RMSE: 0.0084 +- 0.0016\n",
      "Exceed boundary rate: 0.0000 +- 0.0000\n",
      "\n",
      "\n",
      "Running model: Ridge Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   0.276469  0.032161                   0.0\n",
      "1   0.227679  0.047462                   0.0\n",
      "2   0.297830  0.040667                   0.0\n",
      "3   0.274548  0.084597                   0.0\n",
      "4   0.242037  0.061410                   0.0\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 0.2637 +- 0.0283\n",
      "RMSE: 0.0533 +- 0.0205\n",
      "Exceed boundary rate: 0.0000 +- 0.0000\n",
      "\n",
      "\n",
      "Running model: Lasso Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   6.348762  1.145602              0.114848\n",
      "1   2.777140  0.896981              0.132821\n",
      "2   8.994625  3.435741              0.761084\n",
      "3   3.626586  1.517928              0.552764\n",
      "4   7.472153  4.191499              0.860285\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 5.8439 +- 2.6055\n",
      "RMSE: 2.2376 +- 1.4799\n",
      "Exceed boundary rate: 0.4844 +- 0.3474\n",
      "\n",
      "\n",
      "Running model: ElasticNet Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0   5.298294  0.924395              0.069867\n",
      "1   2.777140  0.896981              0.132821\n",
      "2   8.994625  3.435741              0.761084\n",
      "3   3.626586  1.517928              0.552764\n",
      "4   7.472153  4.191499              0.860285\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 5.6338 +- 2.5970\n",
      "RMSE: 2.1933 +- 1.5234\n",
      "Exceed boundary rate: 0.4754 +- 0.3597\n",
      "\n",
      "\n",
      "Running model: Decision Tree Regression\n",
      "Model for motor 6:\n",
      "   Max error      RMSE  Exceed boundary rate\n",
      "0       0.75  0.078164              0.000000\n",
      "1       0.15  0.020624              0.000000\n",
      "2       2.80  0.376778              0.033075\n",
      "3       0.25  0.039651              0.000000\n",
      "4       4.40  1.669094              0.467658\n",
      "\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "Max error: 1.6700 +- 1.8643\n",
      "RMSE: 0.4369 +- 0.7039\n",
      "Exceed boundary rate: 0.1001 +- 0.2059\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "window_size = 50\n",
    "sample_step = 1\n",
    "prediction_lead_time = 1 # We add the temperature measurement up to 1 point before the current time.\n",
    "\n",
    "#all_model_results = run_all_models(df_data=df_data_smoothing, models=models, feature_list=selected_features, threshold=threshold, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, single_run_result=False)\n",
    "\n",
    "all_model_results = run_all_models_motor6(df_data=df_data_smoothing, models=models, feature_list=selected_features, threshold=threshold, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, single_run_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the results - Only using features from the current moment\n",
      "\n",
      "| Model                   | Max error | RMSE  | Exceed boundary rate |\n",
      "|-------------------------|-----------|-------|----------------------|\n",
      "| Linear Regression        |     0.06 |   0.01 |   0.00 |\n",
      "| Ridge Regression         |     0.26 |   0.05 |   0.00 |\n",
      "| Lasso Regression         |     5.84 |   2.24 |   0.48 |\n",
      "| ElasticNet Regression    |     5.63 |   2.19 |   0.48 |\n",
      "| Decision Tree Regression |     1.67 |   0.44 |   0.10 |\n",
      "\n",
      "The best model is Linear Regression with a Mean Squared Error (RMSE) of 0.01.\n"
     ]
    }
   ],
   "source": [
    "summary_data = {\n",
    "    'Model': [],\n",
    "    'Max error': [],\n",
    "    'RMSE': [],\n",
    "    'Exceed boundary rate': []\n",
    "}\n",
    "\n",
    "for model_name, df_results in all_model_results:\n",
    "    max_error = df_results['Max error'].mean()\n",
    "    mse = df_results['RMSE'].mean()\n",
    "    exceed_boundary_rate = df_results['Exceed boundary rate'].mean()\n",
    "    \n",
    "    summary_data['Model'].append(model_name)\n",
    "    summary_data['Max error'].append(f'{max_error:.2f}')\n",
    "    summary_data['RMSE'].append(f'{mse:.2f}')\n",
    "    summary_data['Exceed boundary rate'].append(f'{exceed_boundary_rate:.2f}')\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Summary of the results - Only using features from the current moment\\n\")\n",
    "print(\"| Model                   | Max error | RMSE  | Exceed boundary rate |\")\n",
    "print(\"|-------------------------|-----------|-------|----------------------|\")\n",
    "\n",
    "for model_name, df_results in all_model_results:\n",
    "    max_error = df_results['Max error'].mean()\n",
    "    mse = df_results['RMSE'].mean()\n",
    "    exceed_boundary_rate = df_results['Exceed boundary rate'].mean()\n",
    "    \n",
    "    print(f\"| {model_name.ljust(24)} | {max_error:8.2f} | {mse:6.2f} | {exceed_boundary_rate:6.2f} |\")\n",
    "\n",
    "best_model = summary_df.loc[summary_df['RMSE'].idxmin()]\n",
    "print(f\"\\nThe best model is {best_model['Model']} with a Mean Squared Error (RMSE) of {best_model['RMSE']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the results - Sliding window**\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models. Please write a few texts to explain what is the best model you got (including the features and preprocessing you did), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   (threshold = 1; window_size = 50 ;sample_step = 1 ; prediction_lead_time = 1) | Max error | MRSE | Exceed boundary rate |\n",
    "|---------|----------|-----------|--------|\n",
    "| Linear Regression        |     0.06 |   0.01 |   0.00 |\n",
    "| Ridge Regression         |     0.26 |   0.05 |   0.00 |\n",
    "| Lasso Regression         |     5.84 |   2.24 |   0.48 |\n",
    "| ElasticNet Regression    |     5.63 |   2.19 |   0.48 |\n",
    "| Decision Tree Regression |     1.67 |   0.44 |   0.10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Fault detection based on regression model\n",
    "\n",
    "In this exercise, we use the dataset that contains the failure of motor 6 to test the fault detection model based on the regression model trained before. \n",
    "\n",
    "[This notebook](demo_FaultDetectReg.ipynb) presents a demonstration of how to use the provided supporting function to develop fault detection model based on the regression model. Please have a look at this notebook, and try to improve the performance of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-train the model.\n",
    "# Get all the normal data.\n",
    "normal_test_id = ['20240105_164214', \n",
    "    '20240105_165300', \n",
    "    '20240105_165972', \n",
    "    '20240320_152031', \n",
    "    '20240320_153841', \n",
    "    '20240320_155664', \n",
    "    '20240321_122650', \n",
    "    '20240325_135213',\n",
    "    '20240325_152902', \n",
    "    '20240426_141190', \n",
    "    '20240426_141532', \n",
    "    '20240426_141602', \n",
    "    '20240426_141726', \n",
    "    '20240426_141938', \n",
    "    '20240426_141980', \n",
    "    '20240503_164435']\n",
    "\n",
    "df_tr = df_data[df_data['test_condition'].isin(normal_test_id)]\n",
    "\n",
    "feature_list_all_0 = ['time',\n",
    "                 'data_motor_2_position', \n",
    "                'data_motor_3_position', \n",
    "                'data_motor_4_position', 'data_motor_3_temperature',\n",
    "                  'data_motor_6_temperature']\n",
    "\n",
    "feature_list_all = ['time', 'data_motor_1_position', 'data_motor_1_temperature','data_motor_1_voltage',\n",
    "       'data_motor_1_temperature_diff', 'data_motor_1_voltage_diff','data_motor_1_position_diff', \n",
    "       'data_motor_2_position','data_motor_2_temperature', 'data_motor_2_voltage', \n",
    "       'data_motor_2_temperature_diff', 'data_motor_2_voltage_diff', 'data_motor_2_position_diff',\n",
    "       'data_motor_3_position', 'data_motor_3_temperature','data_motor_3_voltage',\n",
    "       'data_motor_3_temperature_diff', 'data_motor_3_voltage_diff','data_motor_3_position_diff', \n",
    "       'data_motor_4_position','data_motor_4_temperature', 'data_motor_4_voltage',\n",
    "       'data_motor_4_temperature_diff', 'data_motor_4_voltage_diff', 'data_motor_4_position_diff',\n",
    "       'data_motor_5_position', 'data_motor_5_temperature','data_motor_5_voltage',\n",
    "       'data_motor_5_temperature_diff', 'data_motor_5_voltage_diff','data_motor_5_position_diff', \n",
    "       'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage',\n",
    "       'data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff']\n",
    "\n",
    "feature_list_all_2 = ['time','data_motor_1_position', 'data_motor_1_temperature',\n",
    "                'data_motor_2_position', 'data_motor_2_temperature',\n",
    "                'data_motor_3_position',\n",
    "                'data_motor_4_temperature',\n",
    "                'data_motor_5_position', 'data_motor_5_temperature', \n",
    "                'data_motor_6_position', 'data_motor_6_temperature', 'data_motor_6_voltage','data_motor_6_temperature_diff', 'data_motor_6_voltage_diff', 'data_motor_6_position_diff']\n",
    "\n",
    "feature_list_all_3 = ['time','data_motor_1_position', 'data_motor_1_temperature',\n",
    "                'data_motor_2_position', 'data_motor_2_temperature',\n",
    "                'data_motor_3_position','data_motor_3_temperature',\n",
    "                'data_motor_4_temperature','data_motor_4_position',\n",
    "                'data_motor_5_position', 'data_motor_5_temperature', 'data_motor_6_temperature', 'data_motor_6_voltage']\n",
    "\n",
    "# Test data.\n",
    "test_id = [\n",
    "    '20240325_155003',\n",
    "    '20240425_093699',\n",
    "    '20240425_094425',\n",
    "    '20240426_140055',\n",
    "    '20240503_163963',\n",
    "    '20240503_164675',\n",
    "    '20240503_165189'\n",
    "]\n",
    "df_test = df_data[df_data['test_condition'].isin(test_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, steps,param_grid, features, window_size, sample_step, prediction_lead_time, threshold, abnormal_limit, n_fold=7):\n",
    "    print(f'Running model: {name}')\n",
    "    \n",
    "    x_tr_org, y_temp_tr_org = extract_selected_feature(df_data=df_tr, feature_list=features, motor_idx=6, mdl_type='reg')\n",
    "    \n",
    "    x_tr, y_temp_tr = prepare_sliding_window(df_x=x_tr_org, y=y_temp_tr_org, window_size=window_size, sample_step=sample_step, prediction_lead_time=prediction_lead_time, mdl_type='reg')\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(steps)\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=n_fold, scoring='f1', n_jobs=-1)\n",
    "    \n",
    "    grid_search.fit(x_tr, y_temp_tr)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    #mdl = Pipeline(steps).fit(x_tr, y_temp_tr)\n",
    "    \n",
    "    # Define the fault detector\n",
    "    detector_reg = FaultDetectReg(reg_mdl=best_model, threshold=threshold, abnormal_limit=abnormal_limit, window_size=window_size, sample_step=sample_step, pred_lead_time=prediction_lead_time)\n",
    "    \n",
    "    # # Run cross validation\n",
    "    n_fold = 7\n",
    "    _, y_label_test_org = extract_selected_feature(df_data=df_test, feature_list=features, motor_idx=6, mdl_type='clf')\n",
    "    x_test_org, y_temp_test_org = extract_selected_feature(df_data=df_test, feature_list=features, motor_idx=6, mdl_type='reg')\n",
    "    \n",
    "    print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
    "    \n",
    "    motor_idx = 6\n",
    "    print(f'Model for motor {motor_idx}:')\n",
    "    \n",
    "    # Run cross validation.\n",
    "    df_perf = detector_reg.run_cross_val(df_x=x_test_org, y_label=y_label_test_org, y_response=y_temp_test_org, \n",
    "                                        n_fold=n_fold,single_run_result=False)\n",
    "    \n",
    "    print(f'{name} performance:\\n{df_perf}\\n')\n",
    "    print('Mean performance metric and standard error:')\n",
    "    for metric, error in zip(df_perf.mean(), df_perf.std()):\n",
    "        print(f'{metric:.4f} +- {error:.4f}')\n",
    "    print('\\n')\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: Linear Regression\n",
      "Best parameters for Linear Regression: {}\n",
      "Model for motor 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.68s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression performance:\n",
      "   Accuracy  Precision    Recall  F1 score\n",
      "0  0.883870   0.416274  0.570275  0.481254\n",
      "1  0.787879   0.781250  0.914634  0.842697\n",
      "2  0.885033   0.895833  0.666667  0.764444\n",
      "3  0.971429   1.000000  0.571429  0.727273\n",
      "4  0.894286   0.847059  0.829971  0.838428\n",
      "5  0.838000   0.958621  0.868750  0.911475\n",
      "6  0.525074   0.319079  0.457547  0.375969\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "0.8265 +- 0.1442\n",
      "0.7454 +- 0.2691\n",
      "0.6970 +- 0.1754\n",
      "0.7059 +- 0.2007\n",
      "\n",
      "\n",
      "Running model: Ridge Regression\n",
      "Best parameters for Ridge Regression: {'regressor__alpha': 1e-05}\n",
      "Model for motor 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.90s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression performance:\n",
      "   Accuracy  Precision    Recall  F1 score\n",
      "0  0.884786   0.419240  0.570275  0.483231\n",
      "1  0.787879   0.781250  0.914634  0.842697\n",
      "2  0.885033   0.895833  0.666667  0.764444\n",
      "3  0.971429   1.000000  0.571429  0.727273\n",
      "4  0.895238   0.849558  0.829971  0.839650\n",
      "5  0.838000   0.958621  0.868750  0.911475\n",
      "6  0.525074   0.319079  0.457547  0.375969\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "0.8268 +- 0.1444\n",
      "0.7462 +- 0.2687\n",
      "0.6970 +- 0.1754\n",
      "0.7064 +- 0.2005\n",
      "\n",
      "\n",
      "Running model: Lasso Regression\n",
      "Best parameters for Lasso Regression: {'regressor__alpha': 1e-05}\n",
      "Model for motor 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression performance:\n",
      "   Accuracy  Precision    Recall  F1 score\n",
      "0  0.889669   0.432468  0.537964  0.479482\n",
      "1  0.780303   0.778947  0.902439  0.836158\n",
      "2  0.882863   0.894737  0.658915  0.758929\n",
      "3  0.967196   0.944444  0.539683  0.686869\n",
      "4  0.871429   0.789617  0.832853  0.810659\n",
      "5  0.828000   0.960280  0.856250  0.905286\n",
      "6  0.532448   0.324415  0.457547  0.379648\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "0.8217 +- 0.1399\n",
      "0.7321 +- 0.2533\n",
      "0.6837 +- 0.1796\n",
      "0.6939 +- 0.1947\n",
      "\n",
      "\n",
      "Running model: ElasticNet Regression\n",
      "Best parameters for ElasticNet Regression: {'regressor__alpha': 1e-05, 'regressor__l1_ratio': 1e-05}\n",
      "Model for motor 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.75s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression performance:\n",
      "   Accuracy  Precision    Recall  F1 score\n",
      "0  0.888753   0.429124  0.537964  0.477419\n",
      "1  0.780303   0.778947  0.902439  0.836158\n",
      "2  0.882863   0.894737  0.658915  0.758929\n",
      "3  0.967196   0.944444  0.539683  0.686869\n",
      "4  0.871429   0.789617  0.832853  0.810659\n",
      "5  0.828000   0.960280  0.856250  0.905286\n",
      "6  0.532448   0.324415  0.457547  0.379648\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "0.8216 +- 0.1398\n",
      "0.7317 +- 0.2540\n",
      "0.6837 +- 0.1796\n",
      "0.6936 +- 0.1951\n",
      "\n",
      "\n",
      "Running model: Decision Tree Regression\n",
      "Best parameters for Decision Tree Regression: {'regressor__max_depth': 2, 'regressor__min_samples_split': 2}\n",
      "Model for motor 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression performance:\n",
      "   Accuracy  Precision    Recall  F1 score\n",
      "0  0.524035   0.165597  1.000000  0.284140\n",
      "1  0.765152   0.774194  0.878049  0.822857\n",
      "2  0.882863   1.000000  0.581395  0.735294\n",
      "3  0.961905   1.000000  0.428571  0.600000\n",
      "4  0.840000   0.793443  0.697406  0.742331\n",
      "5  0.746000   0.951407  0.775000  0.854191\n",
      "6  0.328909   0.284192  0.754717  0.412903\n",
      "\n",
      "Mean performance metric and standard error:\n",
      "0.7213 +- 0.2212\n",
      "0.7098 +- 0.3453\n",
      "0.7307 +- 0.1877\n",
      "0.6360 +- 0.2155\n",
      "\n",
      "\n",
      "| Model   | Accuracy | Precision | Recall | F1   |\n",
      "|---------|----------|-----------|--------|------|\n",
      "| Linear Regression | 0.83 | 0.75 | 0.70 | 0.71 |\n",
      "| Ridge Regression | 0.83 | 0.75 | 0.70 | 0.71 |\n",
      "| Lasso Regression | 0.82 | 0.73 | 0.68 | 0.69 |\n",
      "| ElasticNet Regression | 0.82 | 0.73 | 0.68 | 0.69 |\n",
      "| Decision Tree Regression | 0.72 | 0.71 | 0.73 | 0.64 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enrich the features based on the sliding window.\n",
    "window_size = 80\n",
    "sample_step = 60\n",
    "prediction_lead_time = 5 \n",
    "threshold = .5\n",
    "abnormal_limit = 3\n",
    "\n",
    "#param_grids = {\n",
    "    #'Linear Regression': [{}],  # Note: GridSearchCV requires at least one parameter grid\n",
    "    #'Ridge Regression': [{'regressor__alpha': np.logspace(-7, 1, num=100)}],# always choose the lowest value\n",
    "    #'Lasso Regression': [{'regressor__alpha': np.logspace(-7, 1, num=100)}],# always choose the lowest value\n",
    "    #'ElasticNet Regression': [{'regressor__alpha': np.logspace(-7, 1, num=100), 'regressor__l1_ratio': np.logspace(-7, 1, num=100)}], # always choose the lowest value\n",
    "    #'Decision Tree Regression': [{'regressor__max_depth': [2,3,4], 'regressor__min_samples_split': [2,3,4]}] # always choose the lowest value\n",
    "#}\n",
    "\n",
    "#fix parameters to run faster, since we already know the best chosen parameters\n",
    "\n",
    "param_grids = {\n",
    "    'Linear Regression': [{}],  # Note: GridSearchCV requires at least one parameter grid\n",
    "    'Ridge Regression': [{'regressor__alpha': [0.00001]}],# always choose the lowest value\n",
    "    'Lasso Regression': [{'regressor__alpha': [0.00001]}],# always choose the lowest value\n",
    "    'ElasticNet Regression': [{'regressor__alpha': [0.00001], 'regressor__l1_ratio': [0.00001]}], # always choose the lowest value\n",
    "    'Decision Tree Regression': [{'regressor__max_depth': [2], 'regressor__min_samples_split': [2]}] # always choose the lowest value\n",
    "}\n",
    "\n",
    "results = []\n",
    "models = [\n",
    "    ('Linear Regression', [('Normalizer', MinMaxScaler()), ('regressor', LinearRegression())]),\n",
    "    ('Ridge Regression', [('Normalizer', MinMaxScaler()), ('regressor', Ridge())]),\n",
    "    ('Lasso Regression', [('Normalizer', MinMaxScaler()), ('regressor', Lasso())]),\n",
    "    ('ElasticNet Regression', [('Normalizer', MinMaxScaler()), ('regressor', ElasticNet())]),\n",
    "    ('Decision Tree Regression', [('regressor', DecisionTreeRegressor())])\n",
    "]\n",
    "\n",
    "for model_name, model_steps in models:\n",
    "    param_grid = param_grids[model_name]\n",
    "    df_perf = evaluate_model(model_name, model_steps,param_grid, feature_list_all_0, window_size, sample_step, prediction_lead_time, threshold, abnormal_limit)\n",
    "    mean_perf = df_perf.mean()\n",
    "    results.append((model_name, mean_perf['Accuracy'], mean_perf['Precision'], mean_perf['Recall'], mean_perf['F1 score']))\n",
    "\n",
    "table_md = \"| Model   | Accuracy | Precision | Recall | F1   |\\n\"\n",
    "table_md += \"|---------|----------|-----------|--------|------|\\n\"\n",
    "for result in results:\n",
    "    model_name, accuracy, precision, recall, f1 = result\n",
    "    table_md += f\"| {model_name} | {accuracy:.2f} | {precision:.2f} | {recall:.2f} | {f1:.2f} |\\n\"\n",
    "\n",
    "print(table_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models (including the unsupervised learning models). Please write a few texts to explain what is the best model you got (including key parameters like threshold, window_size, sample_step, prediction_lead_time, etc), its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Accuracy | Precision | Recall | F1   |\n",
    "|---------|----------|-----------|--------|------|\n",
    "| Linear Regression | 0.83 | 0.75 | 0.70 | 0.71 |\n",
    "| Ridge Regression | 0.83 | 0.75 | 0.70 | 0.71 |\n",
    "| Lasso Regression | 0.82 | 0.73 | 0.68 | 0.69 |\n",
    "| ElasticNet Regression | 0.82 | 0.73 | 0.68 | 0.69 |\n",
    "| Decision Tree Regression | 0.72 | 0.71 | 0.73 | 0.64 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Best model : Linear Regression\n",
    "\n",
    "- window_size = 80\n",
    "\n",
    "- sample_step = 60\n",
    "\n",
    "- prediction_lead_time = 5 \n",
    "\n",
    "- threshold = .5\n",
    "\n",
    "- abnormal_limit = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
