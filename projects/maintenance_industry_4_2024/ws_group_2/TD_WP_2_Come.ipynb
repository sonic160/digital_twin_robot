{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 2\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this WP, you will work on a given training dataset. Your goal is to develop a fault detection model using the classification algorithms learnt in the class, in order to achieve best F1 score.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Develop a fault detection model using the unsupervised learning algorithms learnt in the class, in order to achieve best F1 score.\n",
    "- Task 2: With the help of the supporting script, develop a cross-validation scheme to test the performance of the developed classification algorithms.\n",
    "- Task 3: Develop a fault detection model using the classification algorithms learnt in the class, in order to achieve best F1 score.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the process and results of the above tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch with your name, based on the \"main\" branch and switch to your own branch.\n",
    "- Copy this notebook to the work space of your group, and rename it to TD_WP_2_Your name.ipynb\n",
    "- After finishing this task, push your changes to the github repository of your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Unsupervised learning approaches\n",
    "\n",
    "## Implement the statistical testing approach for fault detection\n",
    "\n",
    "In this exercise, we interpret the statistical testing approach for fault detection. The basic idea of statistical testing approach is that we fit a multi-dimensitional distribution to the observation data under normal working condition. Then, when a new data point arrives, we design a hypothesis test to see whether the new data point is consistent with the distribution. If the new data point is consistent with the distribution, we can conclude that the fault is not due to the faulty component.\n",
    "\n",
    "The benefit of this approach is that, to design the detection algrothim, we do not need failed data. Also, the computational time is short as all we need is just to compute the pdf and compare it to a threshold.\n",
    "\n",
    "In this exercise, you need to:\n",
    "- Fit a multi-dimensitional distribution to the training dataset (all normal samples).\n",
    "- Design a fault detection algorithm based on the fitted distribution to detect faulty components.\n",
    "\n",
    "The following block defines a few functions that you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "def estimateGaussian(X):\n",
    "    '''Given X, this function estimates the parameter of a multivariate Gaussian distribution.'''\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma2 = np.var(X, axis=0)\n",
    "    return mu, sigma2\n",
    "\n",
    "\n",
    "def classify(X, distribution, log_epsilon=-50):\n",
    "    '''Given X, this function classifies each sample in X based on the multivariate Gaussian distribution. \n",
    "       The decision rule is: if the log pdf is less than log_epsilon, we predict 1, as the sample is unlikely to be from the distribution, which represents normal operation.\n",
    "    '''\n",
    "    p = distribution.logpdf(X)\n",
    "    predictions = (p < log_epsilon).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the dataset `20240105_164214` as training dataset, as all the samples in this dataset are normal operation. We will use the dataset `20240325_155003` as testing dataset. Let us try to predict the state of motor 1. For this, we first extract the position, temperature and voltage of motor 1 as features (you can change the features if you want). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../supporting_scripts/WP_1')\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import pandas as pd\n",
    "\n",
    "# Specify path to the dictionary.\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "dictionary_name = '20240105_164214'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_train = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage']]\n",
    "\n",
    "# We do the same to get the test dataset.\n",
    "dictionary_name = '20240325_155003'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_test = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage']]\n",
    "y_test = df_data['data_motor_1_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please design your algorithm below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def get_scores(y_test, y_pred):\n",
    "    f1_sc = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('accuracy score is: ', accuracy)\n",
    "    print('precision is: ', precision)\n",
    "    print('recall is: ', recall)\n",
    "    print('f1 score is: ', f1_sc)\n",
    "    return f1_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score is:  0.4380637402285027\n",
      "precision is:  0.2567621320604614\n",
      "recall is:  0.9992260061919505\n",
      "f1 score is:  0.40854430379746837\n"
     ]
    }
   ],
   "source": [
    "def MVN(X_train, X_test, y_test, eps):\n",
    "    # First, we need to fit a MVN distribution to the normal samples.\n",
    "    mu, sigma2 = estimateGaussian(X_train)\n",
    "\n",
    "    # Construct a multivariate Gaussian distribution to represent normal operation.\n",
    "    distribution = multivariate_normal(mean=mu, cov=np.diag(sigma2), allow_singular = True)\n",
    "\n",
    "    # Now, let's try to predict the labels of the test set X_test.\n",
    "    y_pred = classify(X_test, distribution, log_epsilon=eps)\n",
    "\n",
    "    # Calculate accuracy of the prediction.\n",
    "    f1_sc = get_scores(y_test, y_pred)\n",
    "    return f1_sc\n",
    "MVN(X_train, X_test, y_test, eps = -12500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussions:**\n",
    "- Can you please try to improve the performance of this approach?\n",
    "    - For example, by normalizating the data?\n",
    "    - By smoothing the data?\n",
    "    - By reducing feature number?\n",
    "    - etc.\n",
    "- The parameter log_epsilon defines the threshold we use for making classification. What happens if you change it?\n",
    "- Could you discuss how we should get the best value for this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement by preprocessing : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features based on the TP 1 correlation matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to the dictionary.\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "dictionary_name = '20240105_164214'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_train = df_data[[\"data_motor_2_temperature\", \"data_motor_3_position\", \"data_motor_1_position\", \"data_motor_1_temperature\", \"data_motor_1_voltage\"]]\n",
    "\n",
    "# We do the same to get the test dataset.\n",
    "dictionary_name = '20240325_155003'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_test = df_data[[\"data_motor_2_temperature\", \"data_motor_3_position\", \"data_motor_1_position\", \"data_motor_1_temperature\", \"data_motor_1_voltage\"]]\n",
    "y_test = df_data['data_motor_1_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score is:  0.8624473842453397\n",
      "precision is:  0.7236061684460261\n",
      "recall is:  0.47213622291021673\n",
      "f1 score is:  0.5714285714285714\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[398], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m700000\u001b[39m, \u001b[38;5;241m900000\u001b[39m, \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      4\u001b[0m     score \u001b[38;5;241m=\u001b[39m MVN(X_train, X_test, y_test, eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mk)\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest\u001b[49m:\n\u001b[0;32m      6\u001b[0m         best, esp_best \u001b[38;5;241m=\u001b[39m score, k\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest f1 score :\u001b[39m\u001b[38;5;124m\"\u001b[39m, best)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "eps_best = 0\n",
    "for k in range(700000, 900000, 100):\n",
    "    score = MVN(X_train, X_test, y_test, eps = -k)\n",
    "    if score > best:\n",
    "        best, esp_best = score, k\n",
    "\n",
    "print(\"Best f1 score :\", best)\n",
    "print(\"Pour esp :\", eps_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local outiler factor (LOF)\n",
    "\n",
    "The local outlier factor (LOF) algorithm computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. You can easiliy implement LOF in scikit-learn ([tutorial](https://www.datatechnotes.com/2020/04/anomaly-detection-with-local-outlier-factor-in-python.html)).\n",
    "\n",
    "Please implement local outlier factor (LOF) algorithm on the dataset of `20240325_155003`. You can try first to detect the failure of motor 1 using this model. Please calculate the accuracy score of your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Develop a cross validation pipeline to evaluate the performance of the model.\n",
    "\n",
    "The idea of cross validation is to split the data into k subsets and use one of them as the test set and the rest as the training set. The performance of the model is evaluated only on the test dataset, while the model is trained on the training dataset. By doing this, we ensure that the evaluation of the model is independent from the training of the model. Therefore, we can detect if the model is overfitted.\n",
    "\n",
    "## k-fold cross validation\n",
    "\n",
    "Here, we use motor 1 as an example to develop a pipeline for cross validation. Below, you have a script that read the data, extract features and get the labels.\n",
    "\n",
    "1. Use sk-learn to split the data into training and testing sets, using a k-fold cross validation with k=5. (Hint: This is a routine task which can be answered easily by language models like chatgpt. You can try prompt like this: `Generate a code in python to split the data X and y into training and testing sets, using a k-fold cross validation with k=5.`)\n",
    "2. Then, train a basic logistic regression model, without hyper-parameter tuning on the training set, and use the testing set to evaluate the performance of the model (calculate accuracy, precision, recall, and F1 score). \n",
    "3. Finally, train a logistic regression model, but use the entire dataset X and y as training data. Then, use the trained model to predict the labels of the same dataset (X). Compare the results with the previous step, and discuss why we should use cross validation to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_all_test_data_from_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[392], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m base_dictionary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../dataset/training_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Read all the data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_all_test_data_from_path\u001b[49m(base_dictionary)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract the features for motor 1: You should replace the features with the ones you have selected in WP1.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X \u001b[38;5;241m=\u001b[39m df_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_voltage\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_all_test_data_from_path' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Zhiguo/OneDrive - CentraleSupelec/Code/Python/digital_twin_robot/projects/maintenance_industry_4_2024/supporting_scripts/WP_1')\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import pandas as pd\n",
    "\n",
    "# Specify path to the dictionary.\n",
    "# Define the path to the folder 'collected_data'\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "# Read all the data\n",
    "df_data = read_all_test_data_from_path(base_dictionary)\n",
    "\n",
    "# Extract the features for motor 1: You should replace the features with the ones you have selected in WP1.\n",
    "X = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage']]\n",
    "# Get the label\n",
    "y = df_data['data_motor_1_label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your discussions here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Develop classification-based fault detection models\n",
    "\n",
    "In this task, you are supposed to experiment different classification-based fault detection models to get best F1 score. Please use the 5-fold cross-validation to calculate the best F1 score. You are free to try different models, whether they are discussed in the class or not. To simply your work, you can use the models existed in [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "Please report all the models you tried, how to you tune their hyperparameters, and the corresponding F1 score. Please note that if you would like to tune the hyperparameter, you can use the `GridSearchCv` function in scikit-learn, but you should use it only on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models (including the unsupervised learning models). Please write a few texts to explain what is the best model you got, its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Accuracy | Precision | Recall | F1   |\n",
    "|---------|----------|-----------|--------|------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
