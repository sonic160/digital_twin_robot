{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 2\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This work package aims at developing a data-driven fault detection algorithm for the motors in the robot. The algorithm should be able to accurately detect faults under different working conditions of the robot, and to display the results in the GUI developed in WP1.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Training data generation: Generate training data for your model, considering different working conditions of the robot.\n",
    "- Task 2: Model development.\n",
    "  - Data cleaning, preprocessing\n",
    "  - Investigate different possible model and train the final model\n",
    "- Task 3: GUI design and implementation.\n",
    "- Task 4: Data challenge: Each group will generate a separate dataset, which will be used to construct a final evaluation dataset for the other groups. The performance of your model will be evaluated through this testing dataset.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the model development process, including but not limited to:\n",
    "  - Data cleaning, preprocessing\n",
    "  - The models you tried and their performance evaluation through cross validation\n",
    "  - The final model with best performance\n",
    "- A demo software for condition-monitoring and fault detection:\n",
    "  - The software should be able to read the data from the robot and display the results in the GUI.\n",
    "  - The software should be able to detect faults in the robot and display the results in the GUI.\n",
    "  - Record a video with the robot to demonstrate the functionality of your software.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working plan for today's TD\n",
    "\n",
    "Today, we mainly work on task 2. More specifically, we will work on the following:\n",
    "1. Explore the data we collected last week, including:\n",
    "    - Data visualization to explore the patterns of the data\n",
    "    - Use Principle Component Analysis (PCA) or t-SNE to visualize the data, in order to have a first flavor about the difficulty of the problem \n",
    "    - Explore if we have a significant difference between different sequences through visualization and clustering\n",
    "2. Data cleaning and preprocessing\n",
    "    - Missing values and outlier handling\n",
    "    - Feature engineering\n",
    "3. Apply statistical testing approach.\n",
    "4. Apply a simple logistic regression model as a benchmark model for the classification task.\n",
    "\n",
    "Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch called \"WP2_TD_Lect_6_YourName\", based on the branch \"zhiguo_dev_DARR\" and switch to it.\n",
    "- Copy the notebook WP2_DATA-DRIVEN FAULT DETECTION/support/WP2_TD_Lect_6 to WP2_DATA-DRIVEN FAULT DETECTION/TD_6/, and rename it to TD_Lect_6_YourName.ipynb\n",
    "- After finishing this task, push your changes to your github repository.\n",
    "- Submit a pull request to the \"zhiguo_dev\" branch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 Implement logistic regression\n",
    "\n",
    "Logistic regression is a simple and powerful machine learning algorithm. It is used for classification problems. It is a binary classifier, meaning that it can distinguish between only two classes. Often, it is used as a \"quick and dirty\" method to create benchmark for a classification problem.\n",
    "\n",
    "In this exercise, we will implement logistic regression in our dataset. You will try:\n",
    "- Use sklearn to implement logistic regression\n",
    "- Hyper-parameter tuning in logistic regression\n",
    "- Use cross-validation to evaluate the performance of your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Effect of hyper-parameter and normalization\n",
    "\n",
    "Below is a sample code for logistic regression.\n",
    "- Try to change different values of hyper-parameter $C$, and see the impact on the results.\n",
    "- In this code, we did not do any preprocessing on the data. You can try to implement your preprocessing and see the impacts on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'data_motor_1_position', 'data_motor_1_temperature',\n",
      "       'data_motor_1_voltage', 'data_motor_2_position',\n",
      "       'data_motor_2_temperature', 'data_motor_2_voltage',\n",
      "       'data_motor_3_position', 'data_motor_3_temperature',\n",
      "       'data_motor_3_voltage', 'data_motor_4_position',\n",
      "       'data_motor_4_temperature', 'data_motor_4_voltage',\n",
      "       'data_motor_5_position', 'data_motor_5_temperature',\n",
      "       'data_motor_5_voltage', 'data_motor_6_position',\n",
      "       'data_motor_6_temperature', 'data_motor_6_voltage', 'sequence_idx',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from utility import read_data\n",
    "\n",
    "# Root path to the folder containing the CSV files\n",
    "path_normal = r'../Data collection_20231109/Normal sequence'\n",
    "path_failure = r'../Data collection_20231109/Failure sequence'\n",
    "df = read_data(path_normal, path_failure)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop(['label', 'sequence_idx', 'time'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[331  70]\n",
      " [ 80 238]]\n",
      "Accuracy: 0.7913769123783032\n",
      "Precision: 0.7727272727272727\n",
      "Recall: 0.7484276729559748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zhiguo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:431: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(C=.5)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use $k$-fold cross validation to evaulate the performance\n",
    "\n",
    "In the previous sample code, we used a single train-test split to evaluate the performance of our model. However, in practice, we want to use a more robust method to evaluate the performance of our model. One common method is to use $k$-fold cross validation. In this task, we will use $k$-fold cross validation to evaluate the performance of our model. Please implement a cross-validation with $k=5$, and calculate the average accuracy, precision, recall and F1 score of the tests.\n",
    "\n",
    "This is a routine task which can be easily sovled by current LLM like chatgpt or Tongyi Lingma. I let you try to generate your code by yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Tuning the hyper-parameter of the model\n",
    "\n",
    "We can tune the hyper-parameters of our model by using the GridSearchCV function. You can try to generate the code using the following prompt:\n",
    "\n",
    "```Prompt\n",
    "Tune the hyper-parameter C in a logistic regression model using GridSearchCV. Try a range from 10e-5 to 10. Retrain the model with the best parameters. Then, apply the best model on the testing dataset.\n",
    "\n",
    "Try to implement the generated code on our dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Use the hyper-parameter tuning in cross validation\n",
    "\n",
    "Then, you can improve the classification model in Task 2 by adding the hyper-parameter tuning, and use the best model for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
