{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(folder_path, tmp_path):\n",
    "    \"\"\"\n",
    "    Combine all CSV files in a folder into a single DataFrame.\n",
    "    :param folder_path: Path to the folder containing the CSV files\n",
    "    :param seq_idx: Sequence index\n",
    "    :param label: Label of the sequence (Normal - 0, Abnormal - 1)\n",
    "    :return: A single DataFrame containing all the data from the CSV files\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Create an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the CSV files in the folder\n",
    "    for file in csv_files:\n",
    "        # Construct the full path to each CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Drop the time. Will add later.\n",
    "        df = df.drop(labels=df.columns[0], axis=1)\n",
    "\n",
    "        # Extract the file name (excluding the extension) to use as a prefix\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "\n",
    "        # Add a prefix to each column based on the file name\n",
    "        df = df.add_prefix(f'{file_name}_')\n",
    "\n",
    "        # Concatenate the current DataFrame with the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df['time'], combined_df], axis=1)\n",
    "    combined_df.loc[:, 'test_condition'] = tmp_path\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def load_data(path_header, folder_path):\n",
    "    df = pd.DataFrame()\n",
    "    for tmp_path in folder_path:\n",
    "        # path = path_header + tmp_path\n",
    "        path = path_header + '/' + tmp_path\n",
    "        tmp_df = combine_csv(path, tmp_path)\n",
    "        df = pd.concat([df, tmp_df])\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_and_target_variables(df, training_features, target_variable):\n",
    "    \"\"\"\n",
    "    Separate the features and target variables.\n",
    "    :param df: The DataFrame containing the features and target variables\n",
    "    :param training_features: The names of the training features\n",
    "    :param target_variable: The name of the target variable\n",
    "    :return: A tuple containing the features DataFrame and the target variable Series\n",
    "    \"\"\"\n",
    "    X = df[training_features]\n",
    "    y = df[target_variable]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def standard_scaler(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize the data using StandardScaler.\n",
    "    :param X_train: Training data\n",
    "    :param X_test: Test data\n",
    "    :return: Standardized training and test data\n",
    "    \"\"\"\n",
    "    # Create a StandardScaler object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Standardize the training and test data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def delete_outliers(X, y, threshold=3):\n",
    "    \"\"\"\n",
    "    Delete outliers from the DataFrame.\n",
    "    :param df: The DataFrame containing the features and target variables\n",
    "    :param threshold: The threshold used to identify outliers\n",
    "    :return: The DataFrame with the outliers removed\n",
    "    \"\"\"\n",
    "    # Merge X and y\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Calculate the z-scores for each column\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "\n",
    "    # Find the rows whose z-scores are greater than the threshold\n",
    "    outlier_indices = np.where(z_scores > threshold)[0]\n",
    "\n",
    "    # Delete the rows whose z-scores are greater than the threshold\n",
    "    df = df.drop(df.index[outlier_indices])\n",
    "\n",
    "    # Separate the features and target variables\n",
    "    X = df.drop(y.name, axis=1)\n",
    "    y = df[y.name]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def add_1st_derivative_features(X):\n",
    "    \"\"\"\n",
    "    Add derivative features to the training and test data.\n",
    "    :param X: dataframe in pandas format\n",
    "    :return: Training and test data with the derivative features added\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store the derivative features\n",
    "    X_new = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the columns in the DataFrame\n",
    "    for col in X.columns:\n",
    "        # Calculate the first derivative of the column\n",
    "        first_derivative = np.gradient(X[col])\n",
    "\n",
    "        # Create a new column name for the first derivative\n",
    "        first_derivative_name = col + '_1st_der'\n",
    "\n",
    "        # Add the first derivative to the new DataFrame\n",
    "        X_new[first_derivative_name] = first_derivative\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    X_new = pd.concat([X, X_new], axis=1)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "def oversample_minority_class(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Oversample the minority class using SMOTE.\n",
    "    :param X_train: Training data\n",
    "    :param y_train: Training labels\n",
    "    :return: Oversampled training data and training labels\n",
    "    \"\"\"\n",
    "    # Create an SMOTE object\n",
    "    sm = SMOTE(random_state=42)\n",
    "\n",
    "    # Fit the SMOTE object to the training data and labels\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def smoothen_data(X, window_size):\n",
    "    \"\"\"\n",
    "    Smoothen the data using a moving average.\n",
    "    :param X: Training or test data\n",
    "    :param window_size: Window size for the moving average\n",
    "    :return: Smoothened training or test data\n",
    "    \"\"\"\n",
    "    X_smoothen = X.rolling(window=window_size, min_periods=1).mean()\n",
    "    return X_smoothen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training and target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dict()\n",
    "training_features[\"temperature\"] = list()\n",
    "training_features[\"voltage\"] = list()\n",
    "training_features[\"position\"] = list()\n",
    "training_features[\"solo_motor\"] = dict()\n",
    "target_feature = dict()\n",
    "\n",
    "for i in range(1, 7):\n",
    "    training_features[\"temperature\"].append(\"data_motor_{}_temperature\".format(i))\n",
    "    training_features[\"voltage\"].append(\"data_motor_{}_voltage\".format(i))\n",
    "    training_features[\"position\"].append(\"data_motor_{}_position\".format(i))\n",
    "    training_features[\"solo_motor\"][i] = list()\n",
    "    training_features[\"solo_motor\"][i].append(\"data_motor_{}_temperature\".format(i))\n",
    "    training_features[\"solo_motor\"][i].append(\"data_motor_{}_voltage\".format(i))\n",
    "    training_features[\"solo_motor\"][i].append(\"data_motor_{}_position\".format(i))\n",
    "    target_feature[i] = \"data_motor_{}_label\".format(i)\n",
    "\n",
    "training_features[\"all_num\"] = training_features[\"temperature\"] + training_features[\"voltage\"] + training_features[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data to use for training and testing\n",
    "path_training = [\n",
    "    'fault 1', 'fault 2', 'fault 3', 'fault 4', 'fault 5', 'fault 6',\n",
    "    'static_with_fault_1', 'static_with_fault_2', 'static_with_fault_3', \n",
    "    'static_with_fault_4', 'static_with_fault_5', 'static_with_fault_6', \n",
    "    'steady_state_after_movement', 'steady_state_not_moving',\n",
    "]\n",
    "path_test = ['task_fault']\n",
    "path_header = os.path.abspath('../data_collection/collected_data/')\n",
    "\n",
    "# Load the data\n",
    "df = load_data(path_header, path_training)\n",
    "df_test = load_data(path_header, path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data and find the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a list of classifiers to evaluate\n",
    "classifiers = [\n",
    "    ('LogReg', LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "    # ('SVM', SVC(class_weight='balanced')),\n",
    "    # ('Decision Tree', DecisionTreeClassifier(class_weight='balanced')),\n",
    "    # ('Random Forest', RandomForestClassifier(class_weight='balanced')),\n",
    "    # Add more classifiers here\n",
    "]\n",
    "\n",
    "# Define hyperparameters for grid search for each classifier\n",
    "param_grids = [\n",
    "    {'C': np.logspace(-1, 1, 5)},  # Hyperparameters for Logistic Regression\n",
    "    # {'C': np.logspace(-1, 1, 5), 'gamma': np.logspace(-1, 1, 5), 'kernel': ['poly'], 'degree': [2,3]}, # Hyperparameters for SVM\n",
    "    # {'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4]},  # Hyperparameters for Decision Tree\n",
    "    # {'n_estimators': [10, 50, 100, 200], 'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4]} # Hyperparameters for Random Forest\n",
    "    # Add more hyperparameters for other classifiers here\n",
    "]\n",
    "\n",
    "# Create an empty list to store the results (evaluation metrics) for each classifier\n",
    "val_metrics = dict()\n",
    "\n",
    "# Create the \"models\" directory if it doesn't exist\n",
    "if not os.path.exists(\"models\"):\n",
    "     os.makedirs(\"models\")\n",
    "\n",
    "for chosen_training_method in [\"all_num\", \"solo_motor\", \"temperature\", \"voltage\", \"position\"]:\n",
    "\n",
    "    # Initialize the results dictionary for the current training method\n",
    "    val_metrics[chosen_training_method] = dict()\n",
    "\n",
    "    # Select the data to use for training and testing\n",
    "    X, y = dict(), dict()\n",
    "    X_test, y_test = dict(), dict()\n",
    "    X_train, X_val, y_train, y_val = dict(), dict(), dict(), dict()\n",
    "\n",
    "    for n_motor in range(1, 7):\n",
    "        chosen_target_feature = target_feature[n_motor]\n",
    "        if chosen_training_method == \"solo_motor\":\n",
    "            chosen_training_features = training_features[chosen_training_method][n_motor]\n",
    "        else:\n",
    "            chosen_training_features = training_features[chosen_training_method]\n",
    "        \n",
    "        X[n_motor], y[n_motor] = separate_features_and_target_variables(df, chosen_training_features, chosen_target_feature)\n",
    "        X_test[n_motor], y_test[n_motor] = separate_features_and_target_variables(df_test, chosen_training_features, chosen_target_feature)\n",
    "\n",
    "        # Smoothen the data\n",
    "        X[n_motor] = smoothen_data(X[n_motor], window_size=5)\n",
    "        X_test[n_motor] = smoothen_data(X_test[n_motor], window_size=5)\n",
    "\n",
    "        # Add derivative features\n",
    "        X[n_motor] = add_1st_derivative_features(X[n_motor])\n",
    "        X_test[n_motor] = add_1st_derivative_features(X_test[n_motor])\n",
    "\n",
    "        # Oversample the minority class\n",
    "        X[n_motor], y[n_motor] = oversample_minority_class(X[n_motor], y[n_motor])\n",
    "\n",
    "        # Split the data into training and validating sets\n",
    "        X_train[n_motor], X_val[n_motor], y_train[n_motor], y_val[n_motor] = train_test_split(X[n_motor], y[n_motor], test_size=0.2, random_state=42)\n",
    "\n",
    "        # Initialize the results dictionary for the current motor\n",
    "        val_metrics[chosen_training_method][n_motor] = list()\n",
    "\n",
    "        # Iterate over the classifiers and perform grid search\n",
    "        for classifier, param_grid in zip(classifiers, param_grids):\n",
    "            \n",
    "            # Rename the param_grid keys with the classifier name\n",
    "            param_grid = {f'{classifier[0]}__{key}': value for key, value in param_grid.items()}\n",
    "\n",
    "            # Create a pipeline with Standardization and the current classifier\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                classifier\n",
    "            ])\n",
    "\n",
    "            # Use GridSearchCV to find the best hyperparameters and fit the pipeline\n",
    "            grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', verbose = 1)\n",
    "            grid_search.fit(X_train[n_motor], y_train[n_motor])\n",
    "\n",
    "            # Use grid_search.predict to make predictions on the testing dataset\n",
    "            y_pred = grid_search.predict(X_val[n_motor])\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            conf_matrix = confusion_matrix(y_val[n_motor], y_pred)\n",
    "            accuracy = accuracy_score(y_val[n_motor], y_pred)\n",
    "            precision = precision_score(y_val[n_motor], y_pred)\n",
    "            recall = recall_score(y_val[n_motor], y_pred)\n",
    "            f1 = f1_score(y_val[n_motor], y_pred)\n",
    "\n",
    "            # Store the results in a dictionary\n",
    "            val_result = {\n",
    "                'Classifier': classifier[0],\n",
    "                'Best Parameters': grid_search.best_params_,\n",
    "                'Confusion Matrix': conf_matrix,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            }\n",
    "\n",
    "            # Append the result to the list of results\n",
    "            val_metrics[chosen_training_method][n_motor].append(val_result)\n",
    "\n",
    "            # Save the best model from grid search\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_model_name = f'best_{classifier[0]}_motor_{n_motor}_{chosen_training_method}.model'\n",
    "\n",
    "            # Create the file\n",
    "            file_path = os.path.join(\"models\", best_model_name)\n",
    "            open(file_path, 'w').close()\n",
    "            joblib.dump(best_model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9720394736842105, 0.9029513427279978, 0.8850967007963595, 0.9090909090909091, 0.8506474820143884, 0.8482601254991443]\n"
     ]
    }
   ],
   "source": [
    "training_method = \"temperature\"\n",
    "metric = \"F1 Score\"\n",
    "\n",
    "print([val_metrics[training_method][i][0][metric] for i in range(1, 7)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
