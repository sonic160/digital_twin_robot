{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programmes\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(folder_path, tmp_path):\n",
    "    \"\"\"\n",
    "    Combine all CSV files in a folder into a single DataFrame.\n",
    "    :param folder_path: Path to the folder containing the CSV files\n",
    "    :param seq_idx: Sequence index\n",
    "    :param label: Label of the sequence (Normal - 0, Abnormal - 1)\n",
    "    :return: A single DataFrame containing all the data from the CSV files\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Create an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the CSV files in the folder\n",
    "    for file in csv_files:\n",
    "        # Construct the full path to each CSV file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Drop the time. Will add later.\n",
    "        df = df.drop(labels=df.columns[0], axis=1)\n",
    "\n",
    "        # Extract the file name (excluding the extension) to use as a prefix\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "\n",
    "        # Add a prefix to each column based on the file name\n",
    "        df = df.add_prefix(f'{file_name}_')\n",
    "\n",
    "        # Concatenate the current DataFrame with the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    combined_df = pd.concat([df['time'], combined_df], axis=1)\n",
    "    combined_df.loc[:, 'test_condition'] = tmp_path\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def load_data(path_header, folder_path):\n",
    "    df = pd.DataFrame()\n",
    "    for tmp_path in folder_path:\n",
    "        # path = path_header + tmp_path\n",
    "        path = path_header + '/' + tmp_path\n",
    "        tmp_df = combine_csv(path, tmp_path)\n",
    "        df = pd.concat([df, tmp_df])\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_and_target_variables(df, training_features, target_variable):\n",
    "    \"\"\"\n",
    "    Separate the features and target variables.\n",
    "    :param df: The DataFrame containing the features and target variables\n",
    "    :param training_features: The names of the training features\n",
    "    :param target_variable: The name of the target variable\n",
    "    :return: A tuple containing the features DataFrame and the target variable Series\n",
    "    \"\"\"\n",
    "    X = df[training_features]\n",
    "    y = df[target_variable]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def standard_scaler(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize the data using StandardScaler.\n",
    "    :param X_train: Training data\n",
    "    :param X_test: Test data\n",
    "    :return: Standardized training and test data\n",
    "    \"\"\"\n",
    "    # Create a StandardScaler object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Standardize the training and test data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def delete_outliers(X, y, threshold=3):\n",
    "    \"\"\"\n",
    "    Delete outliers from the DataFrame.\n",
    "    :param df: The DataFrame containing the features and target variables\n",
    "    :param threshold: The threshold used to identify outliers\n",
    "    :return: The DataFrame with the outliers removed\n",
    "    \"\"\"\n",
    "    # Merge X and y\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Calculate the z-scores for each column\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "\n",
    "    # Find the rows whose z-scores are greater than the threshold\n",
    "    outlier_indices = np.where(z_scores > threshold)[0]\n",
    "\n",
    "    # Delete the rows whose z-scores are greater than the threshold\n",
    "    df = df.drop(df.index[outlier_indices])\n",
    "\n",
    "    # Separate the features and target variables\n",
    "    X = df.drop(y.name, axis=1)\n",
    "    y = df[y.name]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def add_1st_derivative_features(X):\n",
    "    \"\"\"\n",
    "    Add derivative features to the training and test data.\n",
    "    :param X: dataframe in pandas format\n",
    "    :return: Training and test data with the derivative features added\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store the derivative features\n",
    "    X_new = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the columns in the DataFrame\n",
    "    for col in X.columns:\n",
    "        # Calculate the first derivative of the column\n",
    "        first_derivative = np.gradient(X[col])\n",
    "\n",
    "        # Create a new column name for the first derivative\n",
    "        first_derivative_name = col + '_1st_der'\n",
    "\n",
    "        # Add the first derivative to the new DataFrame\n",
    "        X_new[first_derivative_name] = first_derivative\n",
    "\n",
    "    # Concatenate the new DataFrame with the original DataFrame\n",
    "    X_new = pd.concat([X, X_new], axis=1)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "def oversample_minority_class(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Oversample the minority class using SMOTE.\n",
    "    :param X_train: Training data\n",
    "    :param y_train: Training labels\n",
    "    :return: Oversampled training data and training labels\n",
    "    \"\"\"\n",
    "    # Create an SMOTE object\n",
    "    sm = SMOTE(random_state=42)\n",
    "\n",
    "    # Fit the SMOTE object to the training data and labels\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def smoothen_data(X, window_size):\n",
    "    \"\"\"\n",
    "    Smoothen the data using a moving average.\n",
    "    :param X: Training or test data\n",
    "    :param window_size: Window size for the moving average\n",
    "    :return: Smoothened training or test data\n",
    "    \"\"\"\n",
    "    X_smoothen = X.rolling(window=window_size, min_periods=1).mean()\n",
    "    return X_smoothen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training and target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dict()\n",
    "training_features[\"temperature\"] = list()\n",
    "training_features[\"voltage\"] = list()\n",
    "training_features[\"position\"] = list()\n",
    "training_features[\"selected_motor\"] = dict()\n",
    "target_feature = dict()\n",
    "\n",
    "for i in range(1, 7):\n",
    "    training_features[\"temperature\"].append(\"data_motor_{}_temperature\".format(i))\n",
    "    training_features[\"voltage\"].append(\"data_motor_{}_voltage\".format(i))\n",
    "    training_features[\"position\"].append(\"data_motor_{}_position\".format(i))\n",
    "    training_features[\"selected_motor\"][i] = list()\n",
    "    training_features[\"selected_motor\"][i].append(\"data_motor_{}_temperature\".format(i))\n",
    "    training_features[\"selected_motor\"][i].append(\"data_motor_{}_voltage\".format(i))\n",
    "    training_features[\"selected_motor\"][i].append(\"data_motor_{}_position\".format(i))\n",
    "    target_feature[i] = \"data_motor_{}_label\".format(i)\n",
    "\n",
    "training_features[\"all_numerical_features\"] = training_features[\"temperature\"] + training_features[\"voltage\"] + training_features[\"position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': ['data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature', 'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature'], 'voltage': ['data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage'], 'position': ['data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', 'data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position'], 'selected_motor': {1: ['data_motor_1_temperature', 'data_motor_1_voltage', 'data_motor_1_position'], 2: ['data_motor_2_temperature', 'data_motor_2_voltage', 'data_motor_2_position'], 3: ['data_motor_3_temperature', 'data_motor_3_voltage', 'data_motor_3_position'], 4: ['data_motor_4_temperature', 'data_motor_4_voltage', 'data_motor_4_position'], 5: ['data_motor_5_temperature', 'data_motor_5_voltage', 'data_motor_5_position'], 6: ['data_motor_6_temperature', 'data_motor_6_voltage', 'data_motor_6_position']}, 'all_numerical_features': ['data_motor_1_temperature', 'data_motor_2_temperature', 'data_motor_3_temperature', 'data_motor_4_temperature', 'data_motor_5_temperature', 'data_motor_6_temperature', 'data_motor_1_voltage', 'data_motor_2_voltage', 'data_motor_3_voltage', 'data_motor_4_voltage', 'data_motor_5_voltage', 'data_motor_6_voltage', 'data_motor_1_position', 'data_motor_2_position', 'data_motor_3_position', 'data_motor_4_position', 'data_motor_5_position', 'data_motor_6_position']}\n"
     ]
    }
   ],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select, read and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data to use for training and testing\n",
    "path_training = ['static_with_fault_1', 'static_with_fault_2', 'static_with_fault_3', \n",
    "'static_with_fault_4', 'static_with_fault_5', 'static_with_fault_6', \n",
    "'steady_state_after_movement', 'steady_state_not_moving'\n",
    "]\n",
    "path_test = ['task_fault']\n",
    "path_header = os.path.abspath('../data_collection/collected_data/')\n",
    "\n",
    "# Load the data\n",
    "df = load_data(path_header, path_training)\n",
    "df_test = load_data(path_header, path_test)\n",
    "\n",
    "# Choose the training method and features\n",
    "# chosen_training_method = \"all_numerical_features\"\n",
    "# chosen_training_method = \"selected_motor\" # Not the same organisation of the data as the others !\n",
    "chosen_training_method = \"temperature\"\n",
    "# chosen_training_method = \"voltage\"\n",
    "# chosen_training_method = \"position\"\n",
    "\n",
    "X, y = dict(), dict()\n",
    "X_test, y_test = dict(), dict()\n",
    "X_train, X_val, y_train, y_val = dict(), dict(), dict(), dict()\n",
    "\n",
    "for n_motor in range(1, 7):\n",
    "    chosen_target_feature = target_feature[n_motor]\n",
    "    if chosen_training_method == \"selected_motor\":\n",
    "        chosen_training_features = training_features[chosen_training_method][n_motor]\n",
    "    else:\n",
    "        chosen_training_features = training_features[chosen_training_method]\n",
    "    \n",
    "    X[i], y[i] = separate_features_and_target_variables(df, chosen_training_features, chosen_target_feature)\n",
    "    X_test[i], y_test[i] = separate_features_and_target_variables(df_test, chosen_training_features, chosen_target_feature)\n",
    "\n",
    "    # Smoothen the data\n",
    "    X[i] = smoothen_data(X[i], window_size=5)\n",
    "    X_test[i] = smoothen_data(X_test[i], window_size=5)\n",
    "\n",
    "    # Add derivative features\n",
    "    X[i] = add_1st_derivative_features(X[i])\n",
    "    X_test[i] = add_1st_derivative_features(X_test[i])\n",
    "\n",
    "    # Oversample the minority class\n",
    "    X[i], y[i] = oversample_minority_class(X[i], y[i])\n",
    "\n",
    "    # Split the data into training and validating sets\n",
    "    X_train[i], X_val[i], y_train[i], y_val[i] = train_test_split(X[i], y[i], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=1000;, score=0.934 total time=   0.1s\n",
      "[CV 2/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=1000;, score=0.929 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=1000;, score=0.927 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=1000;, score=0.936 total time=   0.3s\n",
      "[CV 5/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=1000;, score=0.935 total time=   0.1s\n",
      "[CV 1/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=2000;, score=0.934 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=2000;, score=0.929 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=2000;, score=0.927 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=2000;, score=0.936 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=0.1, Logistic Regression__max_iter=2000;, score=0.935 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=1000;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=1000;, score=0.936 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=1000;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=1000;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=1000;, score=0.945 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=2000;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=2000;, score=0.936 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=2000;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=2000;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=0.31622776601683794, Logistic Regression__max_iter=2000;, score=0.945 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=1000;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=1000;, score=0.946 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=1000;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=1000;, score=0.960 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=1000;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=2000;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=2000;, score=0.946 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=2000;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=2000;, score=0.960 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=1.0, Logistic Regression__max_iter=2000;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=1000;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=1000;, score=0.961 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=1000;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=1000;, score=0.968 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=1000;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=2000;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=2000;, score=0.961 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=2000;, score=0.959 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=2000;, score=0.968 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=3.1622776601683795, Logistic Regression__max_iter=2000;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=1000;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=1000;, score=0.973 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=1000;, score=0.966 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=1000;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=1000;, score=0.972 total time=   0.0s\n",
      "[CV 1/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=2000;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=2000;, score=0.973 total time=   0.0s\n",
      "[CV 3/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=2000;, score=0.966 total time=   0.0s\n",
      "[CV 4/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=2000;, score=0.976 total time=   0.0s\n",
      "[CV 5/5] END Logistic Regression__C=10.0, Logistic Regression__max_iter=2000;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programmes\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Programmes\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Programmes\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model_Logistic Regression_motor_1_temperature.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\Cours CentraleSupelec\\3A - M2\\Data Analytics for Risk and Reliability\\Project\\digital_twin_robot\\course_project_DARR\\WP3_Data challenge preparation\\supports\\fault_detection_model_developement\\create_a_simple_mdl_bis.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Cours%20CentraleSupelec/3A%20-%20M2/Data%20Analytics%20for%20Risk%20and%20Reliability/Project/digital_twin_robot/course_project_DARR/WP3_Data%20challenge%20preparation/supports/fault_detection_model_developement/create_a_simple_mdl_bis.ipynb#X25sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Save the best model from grid search\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/Cours%20CentraleSupelec/3A%20-%20M2/Data%20Analytics%20for%20Risk%20and%20Reliability/Project/digital_twin_robot/course_project_DARR/WP3_Data%20challenge%20preparation/supports/fault_detection_model_developement/create_a_simple_mdl_bis.ipynb#X25sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m best_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/Cours%20CentraleSupelec/3A%20-%20M2/Data%20Analytics%20for%20Risk%20and%20Reliability/Project/digital_twin_robot/course_project_DARR/WP3_Data%20challenge%20preparation/supports/fault_detection_model_developement/create_a_simple_mdl_bis.ipynb#X25sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m joblib\u001b[39m.\u001b[39;49mdump(best_model, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbest_model_\u001b[39;49m\u001b[39m{\u001b[39;49;00mclassifier[\u001b[39m0\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m_motor_\u001b[39;49m\u001b[39m{\u001b[39;49;00mn_motor\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mchosen_training_method\u001b[39m}\u001b[39;49;00m\u001b[39m.model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Programmes\\Anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[39m=\u001b[39mprotocol)\u001b[39m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[39m=\u001b[39mprotocol)\u001b[39m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model_Logistic Regression_motor_1_temperature.model'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a list of classifiers to evaluate\n",
    "classifiers = [\n",
    "    ('Logistic Regression', LogisticRegression(class_weight='balanced')),\n",
    "    # ('SVM', SVC(class_weight='balanced')),\n",
    "    # ('Decision Tree', DecisionTreeClassifier(class_weight='balanced')),\n",
    "    # ('Random Forest', RandomForestClassifier(class_weight='balanced')),\n",
    "    # Add more classifiers here\n",
    "]\n",
    "\n",
    "# Define hyperparameters for grid search for each classifier\n",
    "param_grids = [\n",
    "    {'C': np.logspace(-1, 1, 5), 'max_iter': [100, 200, 500, 1000, 2000]},  # Hyperparameters for Logistic Regression\n",
    "    # {'C': np.logspace(-1, 1, 5), 'gamma': np.logspace(-1, 1, 5), 'kernel': ['poly'], 'degree': [2,3]}, # Hyperparameters for SVM\n",
    "    # {'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4]},  # Hyperparameters for Decision Tree\n",
    "    # {'n_estimators': [10, 50, 100, 200], 'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4]} # Hyperparameters for Random Forest\n",
    "    # Add more hyperparameters for other classifiers here\n",
    "]\n",
    "\n",
    "n_motor = 1\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the classifiers and perform grid search\n",
    "for classifier, param_grid in zip(classifiers, param_grids):\n",
    "    \n",
    "    # Rename the param_grid keys with the classifier name\n",
    "    param_grid = {f'{classifier[0]}__{key}': value for key, value in param_grid.items()}\n",
    "\n",
    "    # Create a pipeline with Standardization and the current classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        classifier\n",
    "    ])\n",
    "\n",
    "    # Use GridSearchCV to find the best hyperparameters and fit the pipeline\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', verbose = 3)\n",
    "    grid_search.fit(X_train[n_motor], y_train[n_motor])\n",
    "\n",
    "    # Use grid_search.predict to make predictions on the testing dataset\n",
    "    y_pred = grid_search.predict(X_test[n_motor])\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    conf_matrix = confusion_matrix(y_test[n_motor], y_pred)\n",
    "    accuracy = accuracy_score(y_test[n_motor], y_pred)\n",
    "    precision = precision_score(y_test[n_motor], y_pred)\n",
    "    recall = recall_score(y_test[n_motor], y_pred)\n",
    "    f1 = f1_score(y_test[n_motor], y_pred)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Classifier': classifier[0],\n",
    "        'Best Parameters': grid_search.best_params_,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    # Append the result to the list of results\n",
    "    results.append(result)\n",
    "\n",
    "    # Save the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    joblib.dump(best_model, f'best_model_{classifier[0]}_motor_{n_motor}_{chosen_training_method}.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
